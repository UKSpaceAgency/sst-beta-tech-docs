---
title: Iterate and improve frequently
weight: 12
hide_in_navigation: true
parent: /ways-of-working
last_reviewed_on: 2022-05-03
review_in: 3 months
---

# 08. Iterate and improve frequently

Make sure you have the capacity, resources and technical flexibility to iterate and improve the service frequently.

### Running your service in a sustainable way

* User research was carried out to identify several key user groups and their key user needs, at both Discovery and Alpha stages of the project. These identified user needs were incorporated into the Beta product, and tested against user experiences with the product.
* We initially launched the product in a private beta in January 2022. However, we continued to develop the product from this point onwards, adding key post-MVP features. This included API access, based on requests from satellite operators and orbital analysts for such a feature.
* The private beta gives the users the opportunity to test the service, identify any technical problems, highlight key areas for improvement and increase usability. The interface was also tested before private beta in a user testing event with 10 students from Cranfield University.
* Overall we have made over 40 releases since public beta started

### Go beyond essential maintenance. Pursue continuous improvement, allowing you to respond to changes in user needs, technology or government policy throughout the lifetime of your service.

* Although a Minimum Viable Product was launched in January 2022, continuous improvement was a key part of the service from January to March 2022.
* Before the product launched, post-MVP features were identified (such as API access, as mentioned above), as well as a menu of additional features. These were based on user needs identified at the Discovery and Alpha stages, as well as conversations with operators and analysts at Beta.
* Following the launch of the product, these additional and post-MVP features were prioritised based on user feedback.

### Budget for uncertainty: Allocate people and resources for continuous improvement in a way that lets teams focus on doing the work that has the most value.

* We have always tried to have the right team available and throughout the project more or less analysis/ ur/ tech team have been available.
* UKSA have allocated their own staff and budgeted for continual improvement, eg by completing a separate tech strategy piece of work so as to understand how to cope with military and development needs of the software.

### Decide where to focus: Service health indicators could include [performance metrics](https://www.gov.uk/service-manual/measuring-success/how-to-set-performance-metrics-for-your-service), analysis of [support tickets](https://userresearch.blog.gov.uk/2018/10/23/how-user-support-ticket-analysis-shapes-what-we-do-on-government-as-a-platform/) and user feedback, [user satisfaction](https://www.gov.uk/service-manual/measuring-success/measuring-user-satisfaction) and web analytics

* Monitor my Satellites uses the third-party service providers Logit and PIWIK Pro to monitor the health of the service.
  * Logit is used to log and monitor errors or system crashes. It takes in metrics from our hosts at GOV.UK PaaS to provide a single radiator view.
  * PIWIK Pro is used to track front-end analytics. It tracks and reports website traffic. It will track user-related metrics.
* Monitor my Satellites also features a feedback page, linked from the Beta banner. Users are asked, “Overall, how did you feel about the service you received today?” and are given the option to provide more details. This feedback is passed onto our team and we will respond and iterate the product based on this. 

<%= partial "partials/links" %>
